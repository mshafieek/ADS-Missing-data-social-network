---
title: "Thesis Project"
author: "Kasper Hermanns"
date: "2024-05-10"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "C:/Users/kaspe/Documents/Applied Data Science (Master)/Thesis 2024/Code")
```


## Loading packages

Here we load all the packages. 

```{r message=FALSE, warning=FALSE, include=FALSE}

# The needed packages, constantly updated
packages <- c("mice","purrr","furrr","dplyr","tibble","remify","remstats","relevent","sna","magrittr","survival","imputeTS","survival","tibble")

 # library("devtools")
 # devtools::install_github("TilburgNetworkGroup/remify")
 # devtools::install_github("gerkovink/mice@match_conditional_current") 
 # devtools::install_github("TilburgNetworkGroup/remstats")

lapply(packages, library,  warn.conflicts = FALSE, character.only=TRUE) # load all the packages


```

## Load in the data

Remove the irrelevant data and rename the 'PartOfApollo_13' data

```{r echo=TRUE, , echo=FALSE}

rm(list=ls())

# set working directory to be the current directory
setwd("~/Applied Data Science (Master)/Thesis 2024/Code")


# Load the data, rename Apollo data and remove the rest of the data
load("UUsummerschool.Rdata")
Apollo <- PartOfApollo_13  %>% 
  rename(
    actor1 = sender,        # These are renamed actor1 and actor2 to match the naming from the 'remify' function used later
    actor2 = receiver
  ) 

rm(Class, PartOfApollo_13, Twitter_data_rem3, WTCPoliceCalls, ClassIntercept, 
   ClassIsFemale, ClassIsTeacher, WTCPoliceIsICR)

head(Apollo)
tail(Apollo)
summary(Apollo)
str(Apollo)

N <- nrow(Apollo)

# Set this as the seed to get the same results every time
set.seed(123)

```


## Visualize Network

With this full data, show the network and its connections


```{r echo=TRUE, , echo=FALSE}

# Make sociomatrix from the Dyadic 
ApolloNet <- as.sociomatrix.eventlist(Apollo,19)

# Make covariate denoting which actors are astronauts or not (last 3 are astronauts)
IsAstronaut <- vector("logical",19)
IsAstronaut[17:19] <- TRUE
IsAstronaut

# And plot it using gplot
gplot(ApolloNet, jitter = TRUE, pad = .075,
              mode = "target", ,vertex.col=ifelse(IsAstronaut ,"blue","red"),
              displaylabels = TRUE, label.pos = 0, label.cex = .75,
              boxed.labels = TRUE, label.pad = .5, 
              displayisolates = TRUE, vertex.cex=.6,
              arrowhead.cex = .75, edge.lwd = -.75, edge.col = "gray") 

```


## Analyse the full dataset to get the true coefficients

Now that there is no missingness (yet), run the analysis to get the true values for the appropriate statistics:
  1. Reciprocity              (PSAB-BA)
  2. Indegree sender          (NIDSnd) 
  3. Outdegree receiver       (NODRec)
  4. Same Location            exogenous tie statistic that is 1 when both sender and receiver are at the same location
  
These are the statistics used for analysis last year, will be changed and updated.


```{r echo=TRUE}

## This function creates a riskset for the given network with calculated statistics according to the given formula. A riskset is a set of all events (dyads) that #have or could have occurred at each timepoint. It should have M (dyads) * N (timepoints) rows and            columns: {time,actor1,actor2,status} + 1 column for each calculated endogenous or exogenous statistic.
riskset_function <- function(network,formula){
  
  # Get the Relational Event History from the network
  REH <- remify(network,  model = 'tie')
  
  # Calculate stats from this REH for each dyad at every timepoint
  dyad_stats <- remstats(REH, tie_effects = formula)
  
  # Get all the dyads from the network and give them corresponding id's
  network_dyads <- attr(dyad_stats, "riskset")  %>% rename(actor1 = sender, actor2 = receiver) 
  
  # Add those id's to the Apollo network to denote which dyad is present
  Apollo_dyads <- merge(network,network_dyads) %>% rename(dyad = id)
  
  # Now we are making our full riskset, this is done by merging the network with the dataframe containing all dyads
  # The results is a dataframe with all dyads at every timepoint, resulting in 240 (dyads) * 3882 (timepoints) = 931680 rows
  riskset <- merge(Apollo_dyads %>% select(time,dyad),network_dyads, by = NULL) %>% arrange(time)
  
  # To this we add the stats calculated for each dyad at every timepoint by remstats.
  riskset$reciprocity <- c(dyad_stats[,,1])
  riskset$indegreeSender <- c(dyad_stats[,,2])
  riskset$outdegreeReceiver <- c(dyad_stats[,,3])
  
  # To finish the riskset, a status variable is created. It denotes which dyad was actually present (1 if so, 0 otherwise) at each timepoint. On top of that, the sameLoc variable is created.
  riskset <- riskset %>% mutate(id = as.integer(id==dyad)) %>% 
                                    rename(status = id) %>% select(-dyad) %>%
                                      mutate(actor1 = as.integer(actor1)) %>%
                                      mutate(actor2 = as.integer(actor2)) %>% 
                                      mutate(sameLoc = ifelse(IsAstronaut[actor1] == IsAstronaut[actor2],1,0)) 
  
  
  return(riskset)
}

# Add order column to Apollo, helps sorting later since the time column needs to be in order
Apollo$order <- 1:nrow(Apollo)

# These will be the statistics that will be studied 
statistics <- ~ -1 + reciprocity(scaling = ("std")) + indegreeSender() + outdegreeReceiver() 

# Create a riskset for the true/full Apollo network using the statistics formula created above
true_riskset <- riskset_function(Apollo,statistics)


## Fit REM model on this riskset using Cox Proportional Hazards model (coxph)
# Old formula for coxph
formula_23 <- Surv(time,status) ~ reciprocity + indegreeSender + outdegreeReceiver

# New and improved formula for coxph, sameLoc added
formula_24 <- Surv(time,status) ~ reciprocity + indegreeSender + outdegreeReceiver + sameLoc


true.fit <- coxph(formula = formula_24, data = true_riskset)


# Fit a Cox Proportional Hazards model on this riskset with both formulas to get the estimates for the statistics of the true network
true.fit1 <- coxph(formula = formula_23, data = true_riskset)
true.fit2 <- coxph(formula = formula_24, data=true_riskset)

summary(true.fit1)
summary(true.fit2)

# Check model fit, using AIC and BIC values (lower is better).
AIC(true.fit1)
AIC(true.fit2)
BIC(true.fit1)
BIC(true.fit2)
# Both the AIC and BIC are lower, so the model fit has improved by adding sameLoc.


# Get the true coefficients for the statistics, these are compared to the coefficients from the amputed datasets to evaluate the imputations
true_coefs_23 <- coefficients(true.fit1)
true_coefs_23

true_coefs_24 <- coefficients(true.fit2)
true_coefs_24


```


## Prepare data for amputing

 <font size="0.1"> am puting these ***** in your ***** </font>

```{r echo=TRUE}

set.seed(123)

# Check how many unique dyads and actors are in the original dataset
remify(Apollo, model = "tie") %>% dim() # 16 actors and 240 dyads

# Need to make sure that the amputed datasets retain those 16 actors and 240 dyads, otherwise they can't be imputed
# For that we need a random base set of (e.g. 1300) rows that we always keep
M <- 1500
base_indic <- sort(sample(1:nrow(Apollo),M))  

# Test if those still retain all the actors and dyads
remify(Apollo[(base_indic),],model = "tie") %>% dim()
# Success! These indices still have all 16 actors and 240 dyads. These can be used as the base set.

# Split the dataset in 2. rest_Apollo can be amputed in whatever way and then combined with base_Apollo and arranged correctly.
base_Apollo <- Apollo[base_indic,]
rest_Apollo <- Apollo[-base_indic,]

comb_Apollo <- rbind(base_Apollo,rest_Apollo) %>%  arrange(order)


```

## Props for the Heist Rocker

This is the function to fix the proportion issue that arose from only running ampute on a part of the dataset

```{r echo=TRUE}

# Lets try out amputing with default settings, just to see what happens. Of course we only ampute rest_Apollo and then combine
MCAR.1 <- ampute(rest_Apollo,prop = .3, mech = "MCAR")$amp
Apollo_miss1 <- rbind(base_Apollo,MCAR.1) %>%  arrange(order)
md.pattern(Apollo_miss1)

# Lets check if the proportion is correct. (Spoiler: Its not)
sum(!complete.cases(Apollo_miss1)) / N
# Wait this is not the proportion we want! Darn it

## Problem!:
# Since the amputing is done on just a part of the dataset, the missingness proportion will not be accurate to the prop value given to the ampute function. This has to be fixed like this:

recalc_prop <- function (desired_prop, totalN, partN){
  rowsMissing <-  totalN * desired_prop # This is the amount of rows that should be missing in the full dataset
  needed_prop <- rowsMissing / partN  # This is the prop missing needed in the partial dataset to recreate the correct prop level
  return(needed_prop)
}

# Now we try this again with the recalculated prop
MCAR.1 <- ampute(rest_Apollo,prop = recalc_prop(0.3,N,N-M), mech = "MCAR")$amp
comb_Apollo <- rbind(base_Apollo,MCAR.1) %>%  arrange(order)
md.pattern(comb_Apollo)

sum(!complete.cases(comb_Apollo)) / N
# This is better!

recalc_prop(0.245,N,N-M)

```


## Amputer? I hardly know her!

Here we start amputing the rest_Apollo in a couple different ways. The settings will be:

- Missingness proportion (rows with missing values) will be 0.3
- We will have all possible combinations of time, actor1 and actor2 as patterns
- The frequency of each pattern will differ
- The mechanism will be MAR.
- Weights will be standard
- Type will differ between pattern, mostly RIGHT-tailed though.

```{r echo=TRUE}

# These are the missingness patterns, the indices column will never be missing of course
myPatterns <- matrix(c(0,0,0,1,
                     0,0,1,1,
                     0,1,0,1,
                     1,0,0,1,
                     1,1,0,1,
                     1,0,1,1,
                     0,1,1,1),
                   nrow = 7,ncol=4,byrow = T)

ampute_dataset <- function(des_prop, patts, mechs, freqs = NULL, weights = NULL, types = NULL){
  
  prop <- recalc_prop(des_prop,N,N-M)
  amp_rest <- ampute(rest_Apollo,prop = prop, patterns = patts, mech = mechs, freq = freqs, weights = weights, type = types)$amp
  amputed_nw <- rbind(base_Apollo,amp_rest) %>%  arrange(order)
  
  return(amputed_nw)
  
}

MCAR.1 <- ampute_dataset(0.3,myPatterns,"MCAR")
md.pattern(MCAR.1)

# Test out the function with different frequencies for the missingness patterns
MCAR.1_5 <- ampute_dataset(0.3,myPatterns,"MCAR",freqs = c(0.1,0.1,0.1,0.1,0.2,0.2,0.2))

md.pattern(MCAR.1_5[1:3])

```

## Mice Mice Baby 

Now we will use multiple imputation with mice to impute those missing values we created above. 


The method will be pmm_conditional, which makes sure that actor1 and actor2 can't be the same id.
Imputing the missing time values will be more complicated, since the correct order needs to be maintained

For now we just interpolate the NA's in time before running MICE. 

```{r echo=TRUE}

# Set these as the methods, time will not have a method as it will be interpolated before running MICE so will have no NA
myMethods1 <- c("","pmm.conditional","pmm.conditional","") 

cond_col <- c("","actor2","actor1","") # Need to specify on which columns each pmm.conditional is conditioned on.
names(cond_col) <- colnames(Apollo)


## Interpolate time before running MICE, this is done by taking the average timepoint(s) between the timepoints before and after the NA(s)
Apollo_time_full <- MCAR.1 %>% mutate(time = na_interpolation(MCAR.1$time))
is.unsorted(Apollo_time_full$time)
md.pattern(Apollo_time_full)
# as you can see it is sorted and no longer any missing values for time.

# Now we set the predictor matrix correctly etc.
imp0 <- mice(Apollo_time_full,printFlag = F)

predMat1 <- imp0$predictorMatrix
predMat1
predMat1[,'order'] <- 0          # Order should not help predict actor1 and actor2
predMat1['time',] <- predMat1['order',] <- 0  # Other variables don't predict order (Superfluous, since it will not be imputed anyway but looks nicer)
predMat1

# And we run MICE
imp1 <- mice(Apollo_time_full, m = 1, method = myMethods1, predictorMatrix = predMat1, whichcolumn = cond_col ,printFlag = F)

Apollo_amp1 <- complete(imp1)
is.unsorted(Apollo_amp1$time)
is.unsorted(Apollo_amp1$order)




```


## Amputing and imputing 100 datasets


```{r echo=TRUE}

myMethods <- c("","pmm.conditional","pmm.conditional","") 


aimpute <- function(N,des_prop, patts, mechs, freqs = NULL, weights = NULL, types = NULL) {
  
  ## Unlike Ampute, the MICE variables stay constant, so they are set here.
  # Here we set the methods used by MICE to impute the variables, atm time will be manually imputed using interpolation
  myMethods <- c("","pmm.conditional","pmm.conditional","")
  cond_col <- c("","actor2","actor1","")
  names(cond_col) <- colnames(Apollo)
  
  # Predictormatrix that will be passed to MICE, atm standard and same as above
  predMat <- predMat1
  
  # Use future_map to run the code to ampute the dataset N times 
  AMP_Apollo <- future_map(1:N, ~ {
    ampute_dataset(des_prop, patts, mechs, freqs, weights, types)
  }, .options = furrr_options(seed = 123))
  
  # Then use future_map to impute all those datasets 5 times with multiple imputation
  IMP_Apollo <- future_map(AMP_Apollo[1:N], ~ {
      mutate(., time = na_interpolation(.$time)) %>% # Interpolate time before running MICE, will be changed later
      mice(m = 5, maxit = 5,         # 5 imputations per amputed df
           method = myMethods,      # This one does not impute time using MICE, been done above
           predictorMatrix = predMat, 
           whichcolumn = cond_col,
           printFlag = F)
  }, .options = furrr_options(seed = 123))
  
  
  return(list(AMPs = AMP_Apollo, IMPs = IMP_Apollo)) # Return the both the amputed and the imputed datasets separately
  
}


# Test the function with MCAR and 2 simulations
MCAR_Apollo <- aimpute(2, 0.3, myPatterns, "MCAR")
test_MICE_MCAR <- MCAR_Apollo$IMPs

# As you can see, the imputation has no missing values
md.pattern(complete(test_MICE_MCAR[[1]]))


```

## Check convergence

Plots waren daar wat plots


```{r echo=TRUE}

## Here we check whether convergence occurred during the multiple imputation of the amputed datasets
convergence <- lapply(test_MICE_MCAR, plot)

# Plot one of the convergence plots, chosen randomly. Done this multiple times to check convergence by eye
convergence[1] 
# Seems like most converged relatively well.

```


## Analysis on MICE datasets

```{r echo=TRUE}

## Made the whole process into a function for easy reproduction
# This function takes K elements of a list of mids (multiple imputed data sets) and fits a model on each. It then averages its results and compares to true_coefs to assess whether valid inference is still possible after using MI.
get_MICE_results <- function(mids_list,K,true_coefs,coxph_formula) {
  
  start_time <- Sys.time()
  
  # Get the results per simulation
  sims_results <-  future_map(mids_list[1:K], ~ {    # Use future to run the following code on the first K mids:
  complete(.x,"all") %>%  # Get all complete datasets
    future_map(~.x %>%    # Run the following code on each imputed complete dataset:
      riskset_function(.,statistics) %$%        # Use the function to get the complete riskset of the REH data
        coxph(formula = coxph_formula, data = .)# Fit the Cox Proportional Hazards model on it with the given formula.
      )  %>%
    pool(custom.t = ".data$b + .data$b / .data$m") %>% # Pool the results from every dataset in the mids together
  .$pooled %>% # extract table of pooled coefficients
        mutate(true = true_coefs, # add true
               df = m-1, # correct df
               riv = Inf, # correct riv
               std.error = sqrt(t), # standard error
               statistic = estimate / std.error, # test statistic
               p.value = 2 * (pt(abs(statistic),
                                 pmax(df, 0.001),
                                 lower.tail = FALSE)), # correct p.value
               `2.5 %` = estimate - qt(.975, df) * std.error, # lower bound CI
               `97.5 %` = estimate + qt(.975, df) * std.error, # upper bound CI
               cov = `2.5 %` < true & true < `97.5 %`, # coverage
               bias = estimate - true,  # raw bias
               PB = 100 * abs(bias/true),  # percent bias
               AW = `97.5 %` -`2.5 %`) %>% # average width
        select(term, m, true, estimate, std.error, statistic, p.value,
               riv, `2.5 %`, `97.5 %`, cov, bias, PB, AW) %>%
        column_to_rownames("term") 
  }) 
  
  # Add all and divide by length to get the average results of the entire mids list.
  avg_results <- Reduce("+", sims_results) / K
  
  # Print computational time
  end_time <- Sys.time()
  print(end_time - start_time)
  
  # Return the results for all sims and the averaged results in 1 named list
  return(list(all = sims_results,avg = avg_results))
  
}


```


## Mice 2 meet you!


```{r echo=TRUE}

setwd("~/Applied Data Science (Master)/Thesis 2024/Code/Results/Sims")

# We will do 100 simulations
K = 100

# MCAR first to test it out
#MCAR_Apollo <- aimpute(K, 0.3, myPatterns, "MCAR")
MCAR_Apollo <- readRDS(file = "C:/Users/kaspe/Documents/Applied Data Science (Master)/Thesis 2024/Code/Results/Sims/MCAR_Apollo.rds")


## Here are our simulation configurations that will be tested. We are first testing different missingness proportions: 0.1, 0.3 & 0.5
#MAR.1_Apollo <- aimpute(K, 0.1, myPatterns, "MAR")
MAR.1_Apollo <- readRDS(file = "C:/Users/kaspe/Documents/Applied Data Science (Master)/Thesis 2024/Code/Results/Sims/MAR.1_Apollo.rds")

#MAR.3_Apollo <- aimpute(K, 0.3, myPatterns, "MAR")
MAR.3_Apollo <- readRDS(file = "C:/Users/kaspe/Documents/Applied Data Science (Master)/Thesis 2024/Code/Results/Sims/MAR.3_Apollo.rds")

#MAR.5_Apollo <- aimpute(K, 0.5, myPatterns, "MAR")
MAR.5_Apollo <- readRDS(file = "C:/Users/kaspe/Documents/Applied Data Science (Master)/Thesis 2024/Code/Results/Sims/MAR.5_Apollo.rds")


## Also test other types of missingness: LEFT & MID
MAR.L_Apollo <- aimpute(K, 0.3, myPatterns, "MAR", types = "LEFT")

MAR.M_Apollo <- aimpute(K, 0.3, myPatterns, "MAR", types = "MID")


## And finally test other frequencies for missingness patterns: mainly 1 missing & mainly 1+ missing


## Save everything!
# setwd("C:/Users/kaspe/Documents/Applied Data Science (Master)/Thesis 2024/Code/Results/Sims/")
# saveRDS(MCAR_Apollo, file = "C:/Users/kaspe/Documents/Applied Data Science (Master)/Thesis 2024/Code/Results/Sims/MCAR_Apollo.rds")
# saveRDS(MAR.1_Apollo, file = "C:/Users/kaspe/Documents/Applied Data Science (Master)/Thesis 2024/Code/Results/Sims/MAR.1_Apollo.rds")
# saveRDS(MAR.3_Apollo, file = "C:/Users/kaspe/Documents/Applied Data Science (Master)/Thesis 2024/Code/Results/Sims/MAR.3_Apollo.rds")
# saveRDS(MAR.5_Apollo, file = "C:/Users/kaspe/Documents/Applied Data Science (Master)/Thesis 2024/Code/Results/Sims/MAR.5_Apollo.rds")
saveRDS(MAR.L_Apollo, file = "C:/Users/kaspe/Documents/Applied Data Science (Master)/Thesis 2024/Code/Results/Sims/MAR.L_Apollo.rds")
saveRDS(MAR.M_Apollo, file = "C:/Users/kaspe/Documents/Applied Data Science (Master)/Thesis 2024/Code/Results/Sims/MAR.M_Apollo.rds")


### BEEP BOOP when done
library(beepr)
beep()


```

## In the mids of getting results




```{r echo=TRUE}


## For all our results, we will be using the true_coefs_24 and formula_24; from 2024 ofc.

# Get the results from the MCAR mids list and save it
#MCAR_results <- get_MICE_results(MCAR_Apollo$IMPs,K,true_coefs_24,formula_24)
MCAR_results <- readRDS(file = "C:/Users/kaspe/Documents/Applied Data Science (Master)/Thesis 2024/Code/Results/MCAR_results.rds")

# Results from MAR
#MAR.1_results <- get_MICE_results(MAR.1_Apollo$IMPs,K,true_coefs_24,formula_24)
MAR.1_results <- readRDS(file = "C:/Users/kaspe/Documents/Applied Data Science (Master)/Thesis 2024/Code/Results/MAR.1_results.rds")

#MAR.3_results <- get_MICE_results(MAR.3_Apollo$IMPs,K,true_coefs_24,formula_24)
MAR.3_results <- readRDS(file = "C:/Users/kaspe/Documents/Applied Data Science (Master)/Thesis 2024/Code/Results/MAR.3_results.rds")

#MAR.5_results <- get_MICE_results(MAR.5_Apollo$IMPs,K,true_coefs_24,formula_24)
MAR.5_results <- readRDS(file = "C:/Users/kaspe/Documents/Applied Data Science (Master)/Thesis 2024/Code/Results/MAR.5_results.rds")

MAR.L_results <- get_MICE_results(MAR.L_Apollo$IMPs,K,true_coefs_24,formula_24)
MAR.L_results <- readRDS(file = "C:/Users/kaspe/Documents/Applied Data Science (Master)/Thesis 2024/Code/Results/MAR.L_results.rds")

MAR.M_results <- get_MICE_results(MAR.M_Apollo$IMPs,K,true_coefs_24,formula_24)
MAR.M_results <- readRDS(file = "C:/Users/kaspe/Documents/Applied Data Science (Master)/Thesis 2024/Code/Results/MAR.M_results.rds")


## Save all the results
saveRDS(MCAR_results, file = "C:/Users/kaspe/Documents/Applied Data Science (Master)/Thesis 2024/Code/Results/MCAR_results.rds")
saveRDS(MAR.1_results, file = "C:/Users/kaspe/Documents/Applied Data Science (Master)/Thesis 2024/Code/Results/MAR.1_results.rds")
saveRDS(MAR.3_results, file = "C:/Users/kaspe/Documents/Applied Data Science (Master)/Thesis 2024/Code/Results/MAR.3_results.rds")
saveRDS(MAR.5_results, file = "C:/Users/kaspe/Documents/Applied Data Science (Master)/Thesis 2024/Code/Results/MAR.5_results.rds")
saveRDS(MAR.L_results, file = "C:/Users/kaspe/Documents/Applied Data Science (Master)/Thesis 2024/Code/Results/MAR.L_results.rds")
saveRDS(MAR.M_results, file = "C:/Users/kaspe/Documents/Applied Data Science (Master)/Thesis 2024/Code/Results/MAR.M_results.rds")


### BEEP BOOP when done
for(i in 1:10){
  beep()
}


```


## Complete Case Analysis (CCA)

CCA Pounder: "Goddamn it Dutch, what other errands do you have us running for the DA!"


```{r echo=TRUE}

## For complete case analysis we also need to ampute the network 100 times, but NOT impute them with multiple imputation. 

# Aimpute the dataset 100 times, then extract the amputed and imputed datasets separately
MCAR.test <- aimpute(100,0.1,myPatterns,"MCAR")

CCA_MCAR1 <- MCAR.test$AMPs
MICE_MCAR1 <- MCAR.test$IMPs


# Test CCA on 1 amputed network
md.pattern(MCAR.1)

CCA_riskset <- riskset_function(MCAR.1,statistics)

CCA.fit <- coxph(formula = formula_24, data = CCA_riskset)
CCA.coef <- coef(CCA.fit)

CCA.fit
CCA.coef

## Run the model on all amputed datasets with CCA

CCA1.fit <- future_map(CCA_MCAR1, ~ {    
                            na.omit(.) %>%
                            riskset_function(.,statistics) %$%
                            coxph(formula = formula_24,.)
                      })


CCA.fit <- CCA_MCAR1 %>%
  future_map(~.x %>%
               na.omit() %>%
               riskset_function(statistics) %$%
               coxph(formula = formula_24,.))

saveRDS(test_results2, file = "test_results2.rds")











##### 

CCA_results <- list()
# Generate 100 dataframes
for (i in 1:100) {
  # Create a dataframe with columns of results from the cox models
  df <- data.frame(
    coef = CCA.fit[[i]]$coefficients,
    se = coef(summary(CCA.fit[[i]]))[, "se(coef)"],
    p = coef(summary(CCA.fit[[i]]))[, "Pr(>|z|)"],
    true = true_coefs_24
  )
  rownames(df) <- c("reciprocity", "indegreeSender", "outdegreeReceiver","sameLoc")
  # Append the dataframe to the list
  CCA_results[[i]] <- df
}
# average the results across all simulations
average <- CCA_results %>%
  map(~.x %>%
        mutate(bias = coef - true) %>% # bias
        select(true, coef, se, p,
               bias)) %>%
  Reduce("+", .) / length(CCA_MCAR1)


 blabla <-  future_map(MICE_MCAR1[1:5], ~ {    # Use future to run the following code on the first K mids:
  complete(.x,"all") %>%  # Get all complete datasets
    future_map(~.x %>%    # Run the following code on each imputed complete dataset:
      riskset_function(.,statistics) %$%        # Use the function to get the complete riskset of the REH data
        coxph(formula = formula_24, data = .)# Fit the Cox Proportional Hazards model on it with the given formula.
      )  %>%
    pool(custom.t = ".data$b + .data$b / .data$m") %>% # Pool the results from every dataset in the mids together
  .$pooled
 })


```





