---
title: "Thesis Project"
author: "Kasper Hermanns"
date: "2024-06-07"
output:
  html_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Loading packages

Here we load all the packages. 

```{r echo=TRUE, message=FALSE, warning=FALSE, error=FALSE, results='hide'}

# The needed packages, constantly updated
packages <- c("mice","purrr","furrr","dplyr","tibble","remify","remstats","relevent","sna","magrittr"
              ,"survival","imputeTS","survival","tibble","ggplot2")

 # library("devtools")
 # devtools::install_github("TilburgNetworkGroup/remify")
 # devtools::install_github("gerkovink/mice@match_conditional_current") 
 # devtools::install_github("TilburgNetworkGroup/remstats")

lapply(packages, library, quietly = TRUE, verbose = FALSE, warn.conflicts = FALSE, character.only=TRUE) # load all the packages


```

## Load in the data

Remove the irrelevant data and rename the 'PartOfApollo_13' data

```{r echo=TRUE}

rm(list=ls())

# set working directory to be the current directory
setwd("~/Applied Data Science (Master)/Thesis 2024/Code")


# Load the data, rename Apollo data and remove the rest of the data
load("UUsummerschool.Rdata")
Apollo <- PartOfApollo_13  %>% 
  rename(
    actor1 = sender,        # These are renamed actor1 and actor2 to match the naming from the 'remify' function used later
    actor2 = receiver
  ) 

rm(Class, PartOfApollo_13, Twitter_data_rem3, WTCPoliceCalls, ClassIntercept, 
   ClassIsFemale, ClassIsTeacher, WTCPoliceIsICR)

head(Apollo)
tail(Apollo)
summary(Apollo)
str(Apollo)

N <- nrow(Apollo)

# Set this as the seed to get the same results every time
set.seed(123)

```


## Visualize Network

With this full data, show the network and its connections


```{r echo=TRUE}

# Make sociomatrix from the Dyadic 
ApolloNet <- as.sociomatrix.eventlist(Apollo,19)

# Make covariate denoting which actors are astronauts or not (last 3 are astronauts)
IsAstronaut <- vector("logical",19)
IsAstronaut[17:19] <- TRUE
IsAstronaut

# And plot it using gplot
gplot(ApolloNet, jitter = TRUE, pad = .075,
              mode = "target", ,vertex.col=ifelse(IsAstronaut ,"blue","red"),
              displaylabels = TRUE, label.pos = 0, label.cex = .75,
              boxed.labels = TRUE, label.pad = .5, 
              displayisolates = TRUE, vertex.cex=.6,
              arrowhead.cex = .75, edge.lwd = -.75, edge.col = "gray") 

```


## Analyse the full dataset to get the true coefficients

Now that there is no missingness (yet), run the analysis to get the true values for the appropriate statistics:
  1. Reciprocity              (PSAB-BA)
  2. Indegree sender          (NIDSnd) 
  3. Outdegree receiver       (NODRec)
  4. Same Location            exogenous tie statistic that is 1 when both sender and receiver are at the same location
  
These are the statistics used for analysis last year, will be changed and updated.


```{r echo=TRUE}

## This function creates a riskset for the given network with calculated statistics according to the given formula. A riskset is a set of all events (dyads) that have or could have occurred at each timepoint. It should have M (dyads) * N (timepoints) rows and columns: {time,actor1,actor2,status} + 1 column for each calculated endogenous or exogenous statistic.
riskset_function <- function(network,formula){
  
  # Get the Relational Event History from the network
  REH <- remify(network,  model = 'tie')
  
  # Calculate stats from this REH for each dyad at every timepoint
  dyad_stats <- remstats(REH, tie_effects = formula)
  
  # Get all the dyads from the network and give them corresponding id's
  network_dyads <- attr(dyad_stats, "riskset")  %>% rename(actor1 = sender, actor2 = receiver) 
  
  # Add those id's to the Apollo network to denote which dyad is present
  Apollo_dyads <- merge(network,network_dyads) %>% rename(dyad = id)
  
  # Now we are making our full riskset, this is done by merging the network with the dataframe containing all dyads
  # The results is a dataframe with all dyads at every timepoint, resulting in 240 (dyads) * 3882 (timepoints) = 931680 rows
  riskset <- merge(Apollo_dyads %>% select(time,dyad),network_dyads, by = NULL) %>% arrange(time)
  
  # To this we add the stats calculated for each dyad at every timepoint by remstats.
  riskset$reciprocity <- c(dyad_stats[,,1])
  riskset$indegreeSender <- c(dyad_stats[,,2])
  riskset$outdegreeReceiver <- c(dyad_stats[,,3])
  
  # To finish the riskset, a status variable is created. It denotes which dyad was actually present (1 if so, 0 otherwise) at each timepoint. On top of that, the sameLoc variable is created which is 1 if both actors are Astronauts or both not Astronauts.
  riskset <- riskset %>% mutate(id = as.integer(id==dyad)) %>% 
                                    rename(status = id) %>% select(-dyad) %>%
                                      mutate(actor1 = as.integer(actor1)) %>%
                                      mutate(actor2 = as.integer(actor2)) %>% 
                                      mutate(sameLoc = ifelse(IsAstronaut[actor1] == IsAstronaut[actor2],1,0)) 
  
    return(riskset) # The full riskset is returned
}

# Add order column to Apollo, helps sorting later since the time column needs to be in order
Apollo$order <- 1:nrow(Apollo)

# These will be the statistics that will be studied 
statistics <- ~ -1 + reciprocity(scaling = ("std")) + indegreeSender() + outdegreeReceiver() 

# Create a riskset for the true/full Apollo network using the statistics formula created above
true_riskset <- riskset_function(Apollo,statistics)


## Fit REM model on this riskset using Cox Proportional Hazards model (coxph)
# # Old formula for coxph
# formula_23 <- Surv(time,status) ~ reciprocity + indegreeSender + outdegreeReceiver

# New and improved formula for coxph, sameLoc added
formula_24 <- Surv(time,status) ~ reciprocity + indegreeSender + outdegreeReceiver + sameLoc


true.fit <- coxph(formula = formula_24, data = true_riskset)


# # Fit a Cox Proportional Hazards model on this riskset with both formulas to get the estimates for the statistics of the true network
# true.fit1 <- coxph(formula = formula_23, data = true_riskset)
# true.fit2 <- coxph(formula = formula_24, data=true_riskset)
# 
# summary(true.fit1)
# summary(true.fit2)
# 
# # Check model fit, using AIC and BIC values (lower is better).
# AIC(true.fit1)
# AIC(true.fit2)
# BIC(true.fit1)
# BIC(true.fit2)
# # Both the AIC and BIC are lower, so the model fit has improved by adding sameLoc.


# Get the true coefficients for the statistics, these are compared to the coefficients from the amputed datasets to evaluate the imputations

true_coefs <- coefficients(true.fit)
true_coefs

```


## Prepare data for amputing

 <font size="0.1"> I am puting this secret message here </font>

```{r echo=TRUE}

# Check how many unique dyads and actors are in the original dataset
remify(Apollo, model = "tie") %>% dim() # 16 actors and 240 dyads

# Need to make sure that the amputed datasets retain those 16 actors and 240 dyads, otherwise they can't be imputed
# For that we need a random base set of (e.g. 1300) rows that we always keep
M <- 1500
base_indic <- sort(sample(1:nrow(Apollo),M))  

# Test if those still retain all the actors and dyads
remify(Apollo[(base_indic),],model = "tie") %>% dim()
# Success! These indices still have all 16 actors and 240 dyads. These can be used as the base set.

# Split the dataset in 2. rest_Apollo can be amputed in whatever way and then combined with base_Apollo and arranged correctly.
base_Apollo <- Apollo[base_indic,]
rest_Apollo <- Apollo[-base_indic,]


```

## Props for the Heist Rocker

This is the function to fix the proportion issue that arose from only running ampute on a part of the dataset

```{r echo=TRUE}

## Problem!:
# Since the amputing is done on just a part of the dataset, the missingness proportion will not be accurate to the prop value given to the ampute function. This has to be fixed like this:
recalc_prop <- function (desired_prop, totalN, partN){
  rowsMissing <-  totalN * desired_prop # This is the amount of rows that should be missing in the full dataset
  needed_prop <- rowsMissing / partN  # This is the prop missing needed in the partial dataset to recreate the correct prop level
  return(needed_prop)
}

```


## Amputer? I hardly know her!

Here is the function used to ampute a dataset. These will be the standard arguments used in ampute() for every amputations

- We will have all possible combinations of time, actor1 and actor2 as patterns: 7 patterns
- The frequency of each pattern is the same: 1/7
- Weights will be the default

The other arguments 'prop', 'mechs'and 'types' will differ between simulations.

```{r echo=TRUE}

# These are the missingness patterns, the order column will never be missing of course
myPatterns <- matrix(c(0,0,0,1,
                     0,0,1,1,
                     0,1,0,1,
                     1,0,0,1,
                     1,1,0,1,
                     1,0,1,1,
                     0,1,1,1),
                   nrow = 7,ncol=4,byrow = T)

ampute_dataset <- function(des_prop, patts, mechs, freqs = NULL, weights = NULL, types = NULL){
  
  prop <- recalc_prop(des_prop,N,N-M)
  amp_rest <- ampute(rest_Apollo,prop = prop, patterns = patts, mech = mechs, freq = freqs, weights = weights, type = types)$amp
  amputed_nw <- rbind(base_Apollo,amp_rest) %>%  arrange(order)
  
  return(amputed_nw)
  
}


# Test out the function with different frequencies for the missingness patterns
test_amp <- ampute_dataset(0.3,myPatterns,"MAR")

md.pattern(test_amp[1:3])

```

## MIce MIce Baby 

The function aimpute is created, which will first make N amputed datasets using the function created above. And then it will impute those using mice. 

The standard setting for mice will be:
The method will be pmm_conditional, which makes sure that actor1 and actor2 can't be the same id.
Imputing the missing time values will be more complicated, since the correct order needs to be maintained, thus these are just interpolated using mean interpolation the NA's in time before running MICE. 


```{r echo=TRUE}

# These are the methods used to impute actor1 and actor2. Time will be imputed not with MI but with mean interpolation.
myMethods <- c("","pmm.conditional","pmm.conditional","") 

# This is the condition matrix, it tells pmm.conditional which variables will be conditioned on which covariates.
cond_col <- c("","actor2","actor1","")
names(cond_col) <- colnames(Apollo)

# Here the predictor matrix is created that will be used in every multiple imputation run.
imp0 <- mice(Apollo,printFlag = F)
predMat <- imp0$predictorMatrix
predMat[,'order'] <- 0            # Order should not help predict actor1 and actor2

# This function will first create N amputed datasets from the Apollo dataset and then use MI to fill in the missing values. 
# This results in a list of N mids, which consist of m = 5 imputed datasets for each simulated missing dataset.
aimpute <- function(N,des_prop, patts, mechs, freqs = NULL, weights = NULL, types = NULL) {
  
   # Use future_map to run the code to ampute the dataset N times 
  AMP_Apollo <- future_map(1:N, ~ {
    ampute_dataset(des_prop, patts, mechs, freqs, weights, types)
  }, .options = furrr_options(seed = 123))
  
  # Then use future_map to impute all those datasets 5 times with multiple imputation
  IMP_Apollo <- future_map(AMP_Apollo[1:N], ~ {
      mutate(., time = na_interpolation(.$time)) %>% # Interpolate time before running MICE, will be changed later
      mice(m = 5, maxit = 5,         # 5 imputations per amputed df
           method = myMethods,      # This one does not impute time using MICE, been done above
           predictorMatrix = predMat, 
           whichcolumn = cond_col,
           printFlag = F)
  }, .options = furrr_options(seed = 123))
  
  
  return(list(AMPs = AMP_Apollo, IMPs = IMP_Apollo)) # Return both the amputed and the imputed datasets separately
  
}

L = 5
# Test the function with MAR and 5 simulations
MCAR_Apollo <- aimpute(L, 0.2, myPatterns, "MAR")
test_MICE_MCAR <- MCAR_Apollo$IMPs

# As you can see, the imputation has no missing values
md.pattern(complete(test_MICE_MCAR[[1]]))


```

## Check convergence


```{r echo=TRUE}

## Here we check whether convergence occurred during the multiple imputation of the amputed datasets
convergence <- lapply(test_MICE_MCAR, plot)

# Plot one of the convergence plots, chosen randomly. Done this multiple times to check convergence by eye
ind_conv <- sample(1:L,1)
ind_conv
convergence[ind_conv] 
# Seems like most converged relatively well.

```


## Analysis on MICE datasets

Here is the function that uses the mids_list created using aimpute, then for K elements make a riskset and run the REM.
These results are then pooled, the evaluation measures are added by comparing them to true_coefs.
Finally the K results are averaged to get a final result, if K = N = 100 that result is for the whole mids_list (a simulation study)


```{r echo=TRUE}

## Made the whole process into a function for easy reproduction
# This function takes K elements of a list of mids (multiple imputed data sets) and fits a model on each. It then averages its results and compares to true_coefs to assess whether valid inference is still possible after using MI.
get_MICE_results <- function(mids_list,K,true_coefs,coxph_formula) {
  
  start_time <- Sys.time()
  
  # Get the results per simulation
  sims_results <-  future_map(mids_list[1:K], ~ {    # Use future to run the following code on the first K mids:
  complete(.x,"all") %>%  # Get all complete datasets
    future_map(~.x %>%    # Run the following code on each imputed complete dataset:
      riskset_function(.,statistics) %$%        # Use the function to get the complete riskset of the REH data
        coxph(formula = coxph_formula, data = .)# Fit the Cox Proportional Hazards model on it with the given formula.
      )  %>%
    pool(custom.t = ".data$b + .data$b / .data$m") %>% # Pool the results from every dataset in the mids together
  .$pooled %>% # extract table of pooled coefficients
        mutate(true = true_coefs, # add true
               df = m-1, # correct df
               riv = Inf, # correct riv
               std.error = sqrt(t), # standard error
               statistic = estimate / std.error, # test statistic
               p.value = 2 * (pt(abs(statistic),
                                 pmax(df, 0.001),
                                 lower.tail = FALSE)), # correct p.value
               `2.5 %` = estimate - qt(.975, df) * std.error, # lower bound CI
               `97.5 %` = estimate + qt(.975, df) * std.error, # upper bound CI
               cov = `2.5 %` < true & true < `97.5 %`, # coverage
               bias = estimate - true,  # raw bias
               PB = 100 * abs(bias/true),  # percent bias
               AW = `97.5 %` -`2.5 %`) %>% # average width
        select(term, m, true, estimate, std.error, statistic, p.value,
               riv, `2.5 %`, `97.5 %`, cov, bias, PB, AW) %>%
        column_to_rownames("term") 
  }) 
  
  # Add all and divide by length to get the average results of the entire mids list.
  avg_results <- Reduce("+", sims_results) / K
  
  # Print computational time. This can take a long time to compute, this shows how long exactly.
  end_time <- Sys.time()
  print(end_time - start_time)
  
  # Return the results for all sims and the averaged results in 1 named list
  return(list(all = sims_results,avg = avg_results))
  
}


```


##  Simulating a missing data problem, then solving it with MI

In this block all the simulations of missing data are created and then imputed, aimpute is used to easily do this.


```{r echo=TRUE}

setwd("~/Applied Data Science (Master)/Thesis 2024/Code/Results/Sims")

# We will do 100 simulations
K = 100

## Here are our simulation configurations that will be tested. We are first testing different missingness proportions: 
# 0.1, 0.2, 0.3, 0.4 & 0.5;  0.2 is gonna be the standard, used in the other simulations

#MAR.1_Apollo <- aimpute(K, 0.1, myPatterns, "MAR")
MAR.1_Apollo <- readRDS(file = "C:/Users/kaspe/Documents/Applied Data Science (Master)/Thesis 2024/Code/Results/Sims/MAR.1_Apollo.rds")

#MAR.2_Apollo <- aimpute(K, 0.2, myPatterns, "MAR")
MAR.2_Apollo <- readRDS(file = "C:/Users/kaspe/Documents/Applied Data Science (Master)/Thesis 2024/Code/Results/Sims/MAR.2_Apollo.rds")

#MAR.3_Apollo <- aimpute(K, 0.3, myPatterns, "MAR")
MAR.3_Apollo <- readRDS(file = "C:/Users/kaspe/Documents/Applied Data Science (Master)/Thesis 2024/Code/Results/Sims/MAR.3_Apollo.rds")

#MAR.4_Apollo <- aimpute(K, 0.4, myPatterns, "MAR")
MAR.4_Apollo <- readRDS(file = "C:/Users/kaspe/Documents/Applied Data Science (Master)/Thesis 2024/Code/Results/Sims/MAR.4_Apollo.rds")

#MAR.5_Apollo <- aimpute(K, 0.5, myPatterns, "MAR")
MAR.5_Apollo <- readRDS(file = "C:/Users/kaspe/Documents/Applied Data Science (Master)/Thesis 2024/Code/Results/Sims/MAR.5_Apollo.rds")


## Also test out MCAR
#MCAR.2_Apollo <- aimpute(K, 0.2, myPatterns, "MCAR")
MCAR.2_Apollo <- readRDS(file = "C:/Users/kaspe/Documents/Applied Data Science (Master)/Thesis 2024/Code/Results/Sims/MCAR.2_Apollo.rds")

## Also test other types of missingness: MID
#MAR.2M_Apollo <- aimpute(K, 0.2, myPatterns, "MAR", types = "MID")
MAR.2M_Apollo <- readRDS(file = "C:/Users/kaspe/Documents/Applied Data Science (Master)/Thesis 2024/Code/Results/Sims/MAR.2M_Apollo.rds")


# ## Save everything!
# setwd("C:/Users/kaspe/Documents/Applied Data Science (Master)/Thesis 2024/Code/Results/Sims/")
# saveRDS(MAR.1_Apollo, file = "C:/Users/kaspe/Documents/Applied Data Science (Master)/Thesis 2024/Code/Results/Sims/MAR.1_Apollo.rds")
# saveRDS(MAR.2_Apollo, file = "C:/Users/kaspe/Documents/Applied Data Science (Master)/Thesis 2024/Code/Results/Sims/MAR.2_Apollo.rds")
# saveRDS(MAR.3_Apollo, file = "C:/Users/kaspe/Documents/Applied Data Science (Master)/Thesis 2024/Code/Results/Sims/MAR.3_Apollo.rds")
# saveRDS(MAR.4_Apollo, file = "C:/Users/kaspe/Documents/Applied Data Science (Master)/Thesis 2024/Code/Results/Sims/MAR.4_Apollo.rds")
# saveRDS(MAR.5_Apollo, file = "C:/Users/kaspe/Documents/Applied Data Science (Master)/Thesis 2024/Code/Results/Sims/MAR.5_Apollo.rds")
# saveRDS(MCAR.2_Apollo, file = "C:/Users/kaspe/Documents/Applied Data Science (Master)/Thesis 2024/Code/Results/Sims/MCAR.2_Apollo.rds")
# saveRDS(MAR.2M_Apollo, file = "C:/Users/kaspe/Documents/Applied Data Science (Master)/Thesis 2024/Code/Results/Sims/MAR.2M_Apollo.rds")


```

## In the mids of getting results

Get an average results for each simulation study made above.

```{r echo=TRUE}


## For all our results, we will be using the true_coefs and formula_24; 

# Use the function get_MICE_results to get an average result for each simulation made above here. 

## Results from the different proportions.
#MAR.1_results <- get_MICE_results(MAR.1_Apollo$IMPs,K,true_coefs,formula_24)
MAR.1_results <- readRDS(file = "C:/Users/kaspe/Documents/Applied Data Science (Master)/Thesis 2024/Code/Results/MAR.1_results.rds")

#MAR.2_results <- get_MICE_results(MAR.2_Apollo$IMPs,K,true_coefs,formula_24)
MAR.2_results <- readRDS(file = "C:/Users/kaspe/Documents/Applied Data Science (Master)/Thesis 2024/Code/Results/MAR.2_results.rds")

#MAR.3_results <- get_MICE_results(MAR.3_Apollo$IMPs,K,true_coefs,formula_24)
MAR.3_results <- readRDS(file = "C:/Users/kaspe/Documents/Applied Data Science (Master)/Thesis 2024/Code/Results/MAR.3_results.rds")

#MAR.4_results <- get_MICE_results(MAR.4_Apollo$IMPs,K,true_coefs,formula_24)
MAR.4_results <- readRDS(file = "C:/Users/kaspe/Documents/Applied Data Science (Master)/Thesis 2024/Code/Results/MAR.4_results.rds")

#MAR.5_results <- get_MICE_results(MAR.5_Apollo$IMPs,K,true_coefs,formula_24)
MAR.5_results <- readRDS(file = "C:/Users/kaspe/Documents/Applied Data Science (Master)/Thesis 2024/Code/Results/MAR.5_results.rds")


### Now run with different proportions
#MCAR.2_results <- get_MICE_results(MCAR.2_Apollo$IMPs,K,true_coefs,formula_24)
MCAR.2_results <- readRDS(file = "C:/Users/kaspe/Documents/Applied Data Science (Master)/Thesis 2024/Code/Results/MCAR.2_results.rds")

#MAR.2M_results <- get_MICE_results(MAR.2M_Apollo$IMPs,K,true_coefs,formula_24)
MAR.2M_results <- readRDS(file = "C:/Users/kaspe/Documents/Applied Data Science (Master)/Thesis 2024/Code/Results/MAR.2M_results.rds")


## Save all the results
# saveRDS(MAR.1_results, file = "C:/Users/kaspe/Documents/Applied Data Science (Master)/Thesis 2024/Code/Results/MAR.1_results.rds")
# saveRDS(MAR.2_results, file = "C:/Users/kaspe/Documents/Applied Data Science (Master)/Thesis 2024/Code/Results/MAR.2_results.rds")
# saveRDS(MAR.3_results, file = "C:/Users/kaspe/Documents/Applied Data Science (Master)/Thesis 2024/Code/Results/MAR.3_results.rds")
# saveRDS(MAR.4_results, file = "C:/Users/kaspe/Documents/Applied Data Science (Master)/Thesis 2024/Code/Results/MAR.4_results.rds")
# saveRDS(MAR.5_results, file = "C:/Users/kaspe/Documents/Applied Data Science (Master)/Thesis 2024/Code/Results/MAR.5_results.rds")
# saveRDS(MCAR.2_results, file = "C:/Users/kaspe/Documents/Applied Data Science (Master)/Thesis 2024/Code/Results/MCAR.2_results.rds")
# saveRDS(MAR.2M_results, file = "C:/Users/kaspe/Documents/Applied Data Science (Master)/Thesis 2024/Code/Results/MAR.2M_results.rds")


# ## BEEP BOOP when done, helps to know when the long computation time is over
# library(beepr)
# for(i in 1:10){
#   beep()
# }


```


## Cya Competent Analysis (CCA)

CCA, or Complete Case Analysis does not use imputation to fill in missing values. It just ignores the rows with missingness.

This block creates a new results function, this one uses the list of amputed datasets instead of the mids_list. 
From these datasets the rows with missing values are removed with na.omit().

After that the process is similar, create a riskset, run the REM, get a result per dataset and then average those.


```{r echo=TRUE}

## For complete case analysis we also need to ampute the network 100 times, but NOT impute them with multiple imputation. 

# This function takes K elements of a list of amputed datasets and fits a model on each with CCA. It then averages its results and compares to true_coefs to assess whether valid inference is still possible after using MI.
get_CCA_results <- function(amp_list,K,true_coefs,coxph_formula) {
  
  start_time <- Sys.time()
  
  # Get the coefficients per simulation
  CCA.fit <- amp_list[1:K] %>%
  future_map(~.x %>%
               na.omit() %>%
               riskset_function(statistics) %$%
               coxph(formula = coxph_formula,.))
  
  CCA_results <- list()
  for(i in 1:K){
    cox <- CCA.fit[[i]]
    
    df <- data.frame(true = true_coefs,
                     estimate = cox$coefficients,
                     std.error = coef(summary(cox))[, "se(coef)"],
                     p.value = coef(summary(cox))[, "Pr(>|z|)"])  %>%  
              mutate(`2.5 %` = confint(cox)[,'2.5 %'],
                     `97.5 %` = confint(cox)[,'97.5 %'],
                    cov = `2.5 %` < true & true < `97.5 %`,          # coverage
                    bias = abs(estimate - true),                          # raw bias
                    PB = 100 * abs(bias/true),                       # percent bias
                    AW = `97.5 %` -`2.5 %`)                          # average width
                    
    CCA_results[[i]] <- df
  } 
  
  # Add all and divide by length to get the average results of the entire mids list.
  avg_results <- Reduce("+", CCA_results) / K
  
  # Print computational time
  end_time <- Sys.time()
  print(end_time - start_time)
  
  # Return the results for all sims and the averaged results in 1 named list
  return(list(all = CCA.fit,avg = avg_results))
  
}




## Run the model on all amputed datasets with CCA

#CCA_MAR.1_results <- get_CCA_results(MAR.1_Apollo$AMPs,K,true_coefs,formula_24)
 CCA_MAR.1_results <- readRDS(file = "C:/Users/kaspe/Documents/Applied Data Science (Master)/Thesis 2024/Code/Results/CCA_MAR.1_results.rds")

#CCA_MAR.2_results <- get_CCA_results(MAR.2_Apollo$AMPs,K,true_coefs,formula_24)
CCA_MAR.2_results <- readRDS(file = "C:/Users/kaspe/Documents/Applied Data Science (Master)/Thesis 2024/Code/Results/CCA_MAR.2_results.rds")

#CCA_MAR.3_results <- get_CCA_results(MAR.3_Apollo$AMPs,K,true_coefs,formula_24)
CCA_MAR.3_results <- readRDS(file = "C:/Users/kaspe/Documents/Applied Data Science (Master)/Thesis 2024/Code/Results/CCA_MAR.3_results.rds")

#CCA_MAR.4_results <- get_CCA_results(MAR.4_Apollo$AMPs,K,true_coefs,formula_24)
CCA_MAR.4_results <- readRDS(file = "C:/Users/kaspe/Documents/Applied Data Science (Master)/Thesis 2024/Code/Results/CCA_MAR.4_results.rds")

#CCA_MAR.5_results <- get_CCA_results(MAR.5_Apollo$AMPs,K,true_coefs,formula_24)
CCA_MAR.5_results <- readRDS(file = "C:/Users/kaspe/Documents/Applied Data Science (Master)/Thesis 2024/Code/Results/CCA_MAR.5_results.rds")

#CCA_MCAR.2_results <- get_CCA_results(MCAR.2_Apollo$AMPs,K,true_coefs,formula_24)
 CCA_MCAR.2_results <- readRDS(file = "C:/Users/kaspe/Documents/Applied Data Science (Master)/Thesis 2024/Code/Results/CCA_MCAR.2_results.rds")
  
#CCA_MAR.2M_results <- get_CCA_results(MAR.2M_Apollo$AMPs,K,true_coefs,formula_24)
CCA_MAR.2M_results <- readRDS(file = "C:/Users/kaspe/Documents/Applied Data Science (Master)/Thesis 2024/Code/Results/CCA_MAR.2M_results.rds")

## save results

# saveRDS(CCA_MAR.1_results, file = "C:/Users/kaspe/Documents/Applied Data Science (Master)/Thesis 2024/Code/Results/CCA_MAR.1_results.rds")
# saveRDS(CCA_MAR.2_results, file = "C:/Users/kaspe/Documents/Applied Data Science (Master)/Thesis 2024/Code/Results/CCA_MAR.2_results.rds")
# saveRDS(CCA_MAR.3_results, file = "C:/Users/kaspe/Documents/Applied Data Science (Master)/Thesis 2024/Code/Results/CCA_MAR.3_results.rds")
# saveRDS(CCA_MAR.4_results, file = "C:/Users/kaspe/Documents/Applied Data Science (Master)/Thesis 2024/Code/Results/CCA_MAR.4_results.rds")
# saveRDS(CCA_MAR.5_results, file = "C:/Users/kaspe/Documents/Applied Data Science (Master)/Thesis 2024/Code/Results/CCA_MAR.5_results.rds")
# saveRDS(CCA_MCAR.2_results, file = "C:/Users/kaspe/Documents/Applied Data Science (Master)/Thesis 2024/Code/Results/CCA_MCAR.2_results.rds")
# saveRDS(CCA_MAR.2M_results, file = "C:/Users/kaspe/Documents/Applied Data Science (Master)/Thesis 2024/Code/Results/CCA_MAR.2M_results.rds")

# ## BEEP BOOP when done, helps to know when the long computation time is over
# for(i in 1:10){
#   beep()
# }




```


### Extract results

From each results df, extract the needed variables into a smaller df.
This is later used for making tables and plotting the results. To visualize the results in a way that is easier to understand.


```{r echo=TRUE}

# Function to extract the results into a single table with the relevant statistics and measures
extract_res <- function(results){
  if(length(results) == 2){ ## MICE results
    
    outcome <- results$avg %>% mutate(Statistic = c("Reciprocity" , "Indegree Sender", "Outdegree Receiver", "Same Location"), 
                             Estimate = estimate, SE = std.error,
                             bias = abs(estimate - true),
                             PB = 100 * abs(bias/true)) %>% 
                      select(c(Statistic,Estimate,SE,p.value,bias,PB,cov,AW))
  } else { # CCA results
     outcome <- results %>% mutate(Statistic = c("Reciprocity" , "Indegree Sender", "Outdegree Receiver", "Same Location"), 
                             Estimate = estimate, SE = std.error,
                             bias = abs(estimate - true),
                             PB = 100 * abs(bias/true)) %>% 
                      select(c(Statistic,Estimate,SE,p.value,bias,PB,cov,AW))
  }
  return(outcome)
}

## Extract all results

# Mice
Mar.1 <- extract_res(MAR.1_results)
Mar.2 <- extract_res(MAR.2_results)
Mar.3 <- extract_res(MAR.3_results)
Mar.4 <- extract_res(MAR.4_results)
Mar.5 <- extract_res(MAR.5_results)
Mcar <- extract_res(MCAR.2_results)
Mar.M <- extract_res(MAR.2M_results)

# CCA
CCA.1 <- extract_res(CCA_MAR.1_results)
CCA.2 <- extract_res(CCA_MAR.2_results)
CCA.3 <- extract_res(CCA_MAR.3_results)
CCA.4 <- extract_res(CCA_MAR.4_results)
CCA.5 <- extract_res(CCA_MAR.5_results)
CCA.mcar <- extract_res(CCA_MCAR.2_results)
CCA.M <- extract_res(CCA_MAR.2M_results)


## Get the true results in a nice table
true_results <- data.frame(Statistic = c("Reciprocity" , "Indegree Sender", "Outdegree Receiver", "Same Location"),
                     Estimate = true.fit$coefficients,
                     SE = coef(summary(true.fit))[, "se(coef)"],
                     p.value = coef(summary(true.fit))[, "Pr(>|z|)"]) 
true_results

```

## Compare results

This block makes DF's containing all the results of the simulation studies per statistic.

1 DF is made cntaining all the simulations with differing proportions; constant: "MAR"
1 DF containing the different mechanisms; constant: prop = 0.2

```{r echo=TRUE}

## Add all results in a single dataframe using the function below, each row will be the result for 1 statistics, of 1 sim study.
# It fills the DF with different results based on whether 'mechs' is true or not.
add_results <- function(DF,statistic,mech){
  
  if(mech){
    DF[nrow(DF)+1,] <- c(statistic,"MI","MCAR",0.2,c(Mcar[statistic,2:8]))
    DF[nrow(DF)+1,] <- c(statistic,"MI","MAR",0.2,c(Mar.2[statistic,2:8]))
    DF[nrow(DF)+1,] <- c(statistic,"MI","MAR.M",0.2,c(Mar.M[statistic,2:8]))
    
    DF[nrow(DF)+1,] <- c(statistic,"CCA","MCAR",0.2,c(CCA.mcar[statistic,2:8]))
    DF[nrow(DF)+1,] <- c(statistic,"CCA","MAR",0.2,c(CCA.2[statistic,2:8]))
    DF[nrow(DF)+1,] <- c(statistic,"CCA","MAR.M",0.2,c(CCA.M[statistic,2:8]))
  }
  
  else {
  DF[nrow(DF)+1,] <- c(statistic,"MI","MAR",0.1,c(Mar.1[statistic,2:8]))
  DF[nrow(DF)+1,] <- c(statistic,"MI","MAR",0.2,c(Mar.2[statistic,2:8]))
  DF[nrow(DF)+1,] <- c(statistic,"MI","MAR",0.3,c(Mar.3[statistic,2:8]))
  DF[nrow(DF)+1,] <- c(statistic,"MI","MAR",0.4,c(Mar.4[statistic,2:8]))
  DF[nrow(DF)+1,] <- c(statistic,"MI","MAR",0.5,c(Mar.5[statistic,2:8]))
  
  DF[nrow(DF)+1,] <- c(statistic,"CCA","MAR",0.1,c(CCA.1[statistic,2:8]))
  DF[nrow(DF)+1,] <- c(statistic,"CCA","MAR",0.2,c(CCA.2[statistic,2:8]))
  DF[nrow(DF)+1,] <- c(statistic,"CCA","MAR",0.3,c(CCA.3[statistic,2:8]))
  DF[nrow(DF)+1,] <- c(statistic,"CCA","MAR",0.4,c(CCA.4[statistic,2:8]))
  DF[nrow(DF)+1,] <- c(statistic,"CCA","MAR",0.5,c(CCA.5[statistic,2:8]))
  }
  
  return(DF)
}

## Initialize the results_DF's, then fill them with the corresponding results. 
results_DF_prop <- results_DF_mech <- data.frame(Stat = row.names(true_results), Test = "True", Mech = NA, Prop = 0, c(true_results[,2:4]),bias = NA, PB = NA, CR = NA, AW = NA)

# DF for prop results
for (stat in row.names(true_results)) {
  results_DF_prop <- add_results(results_DF_prop,stat,FALSE)
}
results_DF_prop <- results_DF_prop[-c(1:4),] # remove the true_results

# DF for mechanism results
for (stat in row.names(true_results)) {
  results_DF_mech <- add_results(results_DF_mech,stat,TRUE)
}
results_DF_mech <- results_DF_mech[-c(1:4),] # remove the true_results

```


### Plot PB vs Missingness Proportions, 1 plot for each of the 4 statistics


```{r}

# Plot PB vs Missingness Proportion for each statistic
plot_PB.Prop <- ggplot(results_DF_prop, aes(x = Prop, y = PB, colour = Test)) +
  geom_line() +
  geom_hline(aes(yintercept = 5), linetype = "dotted") +
  labs(title = "Percent Bias (PB) vs Missingness Proportion for each statistic. PB should be <5%",y = "PB",x="Missingness Proportion") +
  facet_wrap(. ~ Stat) +
  scale_y_log10(breaks = c(0,1,5,10,25,100)) +
  theme_bw()

my_theme <- theme(title = element_text(size=10), axis.title=element_text(size=12)) 

plot_PB.Prop + my_theme

```


### Plot PB vs Mechanisms, 1 plot for each of the 4 statistics


```{r echo=TRUE}

# Plot PB vs Mechanisms for each statistic
plot_PB.Mech <- ggplot(results_DF_mech, aes(x = Mech, y = PB, colour = Test)) +
  geom_point() +
  geom_hline(aes(yintercept = 5), linetype = "dotted") +
  labs(title = "Percent Bias (PB) vs Missingness Proportion for each statistic. PB should be <5%",y = "PB",x="Missingness Proportion") +
  facet_wrap(. ~ Stat) +
  scale_y_log10(breaks = c(0,1,5,10,25,100)) +
  theme_bw()

plot_PB.Mech + my_theme


```




